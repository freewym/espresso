# @package _group_

common:
  amp: true
  log_format: simple
  log_interval: 1000
  seed: 1
  empty_cache_freq: 10

checkpoint:
  save_dir: checkpoints
  save_interval_updates: 750
  keep_interval_updates: 3
  keep_last_epochs: 5
  best_checkpoint_metric: wer

task:
  _name: speech_recognition_espresso
  data: ???
  dict: ???
  max_source_positions: 3600
  max_target_positions: 200
  autoregressive: false
  global_cmvn_stats_path:
  specaugment_config:

dataset:
  num_workers: 6
  max_tokens: 26000
  batch_size: 24
  required_batch_size_multiple: 1
  data_buffer_size: 100
  train_subset: train
  valid_subset: valid
  batch_size_valid: 48
  curriculum: 1

distributed_training:
  distributed_world_size: 8
  ddp_backend: legacy_ddp

criterion:
  _name: ctc_loss
  zero_infinity: true
  print_training_sample_interval: 500

optimization:
  max_epoch: 100
  clip_norm: 2.0
  sentence_avg: true
  update_freq: [1]
  lr: [5.0]

optimizer:
  _name: adam
  adam_betas: (0.9,0.98)
  adam_eps: 1e-08
  weight_decay: 0.0

lr_scheduler:
  _name: noam
  warmup_steps: 25000
  model_size: ${model.encoder.embed_dim}
  final_lr: 1e-6

model:
  _name: speech_transformer_encoder_model
  encoder:
    conv_channels: "[64, 64, 128, 128]"
    conv_kernel_sizes: "[(3, 3), (3, 3), (3, 3), (3, 3)]"
    conv_strides: "[(1, 1), (2, 2), (1, 1), (2, 2)]"
    embed_dim: 512
    ffn_embed_dim: 2048
    layers: 12
    attention_heads: 8
    normalize_before: true
    learned_pos: false
    relative_positional_embeddings: true
  attention_dropout: 0.1
  activation_dropout: 0.1
  dropout: 0.1
  activation_fn: relu
  layernorm_embedding: true

bpe:
  _name: sentencepiece
  sentencepiece_model: ???
